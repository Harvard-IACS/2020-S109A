{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <img style=\"float: left; padding-right: 10px; width: 45px\" src=\"https://github.com/Harvard-IACS/2018-CS109A/blob/master/content/styles/iacs.png?raw=true\"> CS-S109A Introduction to Data Science \n",
    "\n",
    "## Lecture 2 (Pandas + Beautiful Soup)\n",
    "\n",
    "**Harvard University**<br>\n",
    "**Summer 2020**<br>\n",
    "**Instructors:** Kevin Rader<br>\n",
    "**Authors:** Rahul Dave, David Sondak, Will Claybaugh, Pavlos Protopapas, Chris Tanner, Kevin Rader\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "blockquote { background: #AEDE94; }\n",
       "h1 { \n",
       "    padding-top: 25px;\n",
       "    padding-bottom: 25px;\n",
       "    text-align: left; \n",
       "    padding-left: 10px;\n",
       "    background-color: #DDDDDD; \n",
       "    color: black;\n",
       "}\n",
       "h2 { \n",
       "    padding-top: 10px;\n",
       "    padding-bottom: 10px;\n",
       "    text-align: left; \n",
       "    padding-left: 5px;\n",
       "    background-color: #EEEEEE; \n",
       "    color: black;\n",
       "}\n",
       "\n",
       "div.exercise {\n",
       "\tbackground-color: #ffcccc;\n",
       "\tborder-color: #E9967A; \t\n",
       "\tborder-left: 5px solid #800080; \n",
       "\tpadding: 0.5em;\n",
       "}\n",
       "\n",
       "span.sub-q {\n",
       "\tfont-weight: bold;\n",
       "}\n",
       "div.theme {\n",
       "\tbackground-color: #DDDDDD;\n",
       "\tborder-color: #E9967A; \t\n",
       "\tborder-left: 5px solid #800080; \n",
       "\tpadding: 0.5em;\n",
       "\tfont-size: 18pt;\n",
       "}\n",
       "div.gc { \n",
       "\tbackground-color: #AEDE94;\n",
       "\tborder-color: #E9967A; \t \n",
       "\tborder-left: 5px solid #800080; \n",
       "\tpadding: 0.5em;\n",
       "\tfont-size: 12pt;\n",
       "}\n",
       "p.q1 { \n",
       "    padding-top: 5px;\n",
       "    padding-bottom: 5px;\n",
       "    text-align: left; \n",
       "    padding-left: 5px;\n",
       "    background-color: #EEEEEE; \n",
       "    color: black;\n",
       "}\n",
       "header {\n",
       "   padding-top: 35px;\n",
       "    padding-bottom: 35px;\n",
       "    text-align: left; \n",
       "    padding-left: 10px;\n",
       "    background-color: #DDDDDD; \n",
       "    color: black;\n",
       "}\n",
       "</style>\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## RUN THIS CELL TO GET THE RIGHT FORMATTING \n",
    "import requests\n",
    "from IPython.core.display import HTML\n",
    "styles = requests.get(\"https://raw.githubusercontent.com/Harvard-IACS/2018-CS109A/master/content/styles/cs109.css\").text\n",
    "HTML(styles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents \n",
    "<ol start=\"0\">\n",
    "<li> Learning Goals </li>\n",
    "<li> Data without Pandas </li>\n",
    "<li> Loading and Cleaning with Pandas  </li>\n",
    "<li> Combinng Data Sources </li>\n",
    "<li> Basic Scraping with Beautiful Soup </li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Goals\n",
    "\n",
    "This Jupyter notebook accompanies Lecture 2. By the end of this lecture, you should be able to:\n",
    "\n",
    "- Appreciate that base Python is not great for most data handling.\n",
    "- Understand why and how Pandas can be useful. \n",
    "- Use Pandas to:\n",
    "    - Load data into a DataFrame\n",
    "    - Access subsets of data based on column and row values\n",
    "    - Address missing values (e.g., `NaN`)\n",
    "    - Use `groupby()` to select sections of data.\n",
    "    - Plot DataFrames (e.g., barplot())\n",
    "- Use Beautiful Soup to download a webpage and all of its links, and begin to learn parse out tables, links, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Processing Data without Pandas \n",
    "\n",
    "`../data/top50.csv` is a dataset found online (Kaggle.com) that contains information about the 50 most popular songs on Spotify in 2019.\n",
    "\n",
    "Each row represents a distinct song.\n",
    "The columns (in order) are:\n",
    "```\n",
    "ID: a unique ID (i.e., 1-50)\n",
    "TrackName: Name of the Track\n",
    "ArtistName: Name of the Artist\n",
    "Genre: the genre of the track\n",
    "BeatsPerMinute: The tempo of the song.\n",
    "Energy: The energy of a song - the higher the value, the more energetic. song\n",
    "Danceability: The higher the value, the easier it is to dance to this song.\n",
    "Loudness: The higher the value, the louder the song.\n",
    "Liveness: The higher the value, the more likely the song is a live recording.\n",
    "Valence: The higher the value, the more positive mood for the song.\n",
    "Length: The duration of the song (in seconds).\n",
    "Acousticness: The higher the value, the more acoustic the song is.\n",
    "Speechiness: The higher the value, the more spoken words the song contains.\n",
    "Popularity: The higher the value, the more popular the song is.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.open(\"fig/top50_screenshot.png\") # sample of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read and store `../data/top50.csv`\n",
    "\n",
    "**Q1.1:** Read in the `../data/top50.csv` file and store all of its contents into any data structure(s) that make the most sense to you, keeping in mind that you'd want to easily access any row or column.  Why does a dictionary make the most sense to use for data storage?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"../data/top50.csv\")\n",
    "column_names = f.readline().strip().split(\",\")[1:] # puts names in a list\n",
    "cleaned_column_names = [name for name in column_names] # removes the extraneous quotes\n",
    "cleaned_column_names.insert(0, \"ID\")\n",
    "\n",
    "dataset = []\n",
    "\n",
    "# iterates through each line of the .csv file\n",
    "for line in f:\n",
    "    attributes = line.strip().split(\",\")\n",
    "    \n",
    "    # constructs a new dictionary for each line, and\n",
    "    # appends this dictionary to the `dataset`;\n",
    "    # thus, the dataset is a list of dictionaries (1 dictionary per song)\n",
    "    dataset.append(dict(zip(cleaned_column_names, attributes)))\n",
    "    \n",
    "# dataset[0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q1.2:** Write code to print all songs (Artist and Track name) that are longer than 4 minutes (240 seconds):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "########\n",
    "# your code below: uncomment and fill in the ****\n",
    "########\n",
    "\n",
    "#for song in ****:\n",
    "     #if int(song[****] > ****) :\n",
    "        # print(****, \"-\", ****, \"is\", **** ,\"seconds long\")\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q1.3:** Write code to print the most popular song (or song(s) if there is a tie):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "########\n",
    "# your code below: uncomment and fill in the ****\n",
    "########\n",
    "\n",
    "max_score = -1\n",
    "most_populars = set()\n",
    "# for ***:\n",
    "#    if int(song[\"Popularity\"]) > max_score:\n",
    "#        most_populars = set([str(song[\"ArtistName\"] + \"-\" + song[\"TrackName\"])])\n",
    "#        max_score = int(song[\"Popularity\"])\n",
    "    # elif ****:\n",
    "    #    most_populars.add(****)\n",
    "# print(most_populars)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q1.4:** How would you print the songs (and their attributes) in sorted order by their popularity (highest scoring ones first)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q1.5**: How could you check for null/empty entries?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Often times, one dataset doesn't contain all of the information you are interested in -- in which case, you need to combine data from multiple files.\n",
    "\n",
    "**Q1.6:** Imagine we had another table (i.e., .csv file) below. How could we combine its data with our already-existing *dataset*?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Processing Data _with_ Pandas "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pandas** is an _open-source_ Python library designed for **data analysis and processing.** Being _open-sourced_ means that anyone can contribute to it (don't worry, a team of people vett all official updates to the library). Pandas allows for high-performance, easy-to-use data structures. Namely, instead of using N-dimensional arrays like NumPy (which are extremely fast, though), Pandas provides a 2D-table object calleda **DataFrame**.\n",
    "\n",
    "As a very gross simplification: **NumPy** is great for performing math operations with matrices, whereas **Pandas** is excellent for wrangling, processing, and understanding 2D data like spreadsheets (2D data like spreadsheets is very common and great).\n",
    "\n",
    "Let's get started with simple examples of how to use Pandas. We will continue with our ``top50.csv`` Spotify music data.\n",
    "\n",
    "First, we need to import pandas so that we have access to it. For typing convenience, we choose to rename it as ``pd``, which is common practice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "pd.set_option('display.width', 500)\n",
    "pd.set_option('display.max_columns', 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading in the data\n",
    "Pandas allows us to [read in various structured files](https://pandas.pydata.org/pandas-docs/stable/user_guide/io.html) (e.g., .csv, .json, .html, etc) with just one line:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we don't always need to specify the encoding, but this particular\n",
    "# file has special characters that we need to handle\n",
    "top50 = pd.read_csv(\"../data/top50.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### High-level view of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can view the data frame by simply printing it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that we can also inspect the file by looking at just the first N rows or last N rows (instead of printing the entire dataframe)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top50.head(5) # first 5 rows\n",
    "top50.tail(3) # last 3 rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q2.1:** That's cool, but we can't see all of the columns too well. Write code to print out the columns of 'top50' and the code to calculate number of columns in it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######\n",
    "# your code here\n",
    "######\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fortunately, many of the features in our dataset are numeric. Conveniently, Pandas' `describe()` function calculates basic statistics for our columns. It's pretty amazing, as it allows us a very coarse-grain approach to understanding our data and checking for errors. That is, if we notice any summary statistics that are drastically different than what we deem reasonable, we should dive deeper and figure out why the values are what they are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top50.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q2.2:** Which of the variable above appears to be the most skewed?  Investigate its skew with a histogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######\n",
    "# your code here\n",
    "######\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*your answer here* \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice, it calculated statistics only for the columns that are of numeric data types. What about the textual ones (e.g., Track name and Artist)? Pandas is smart enough to infer the data types. **Don't forget to inspect the columns that are text-based though, as we need to ensure they are sound, too.**\n",
    "\n",
    "To view the data type of each column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "top50.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q2.3:** Write code to obtain the table of frequencies for any categorical variables in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######\n",
    "# your code here\n",
    "#######\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I agree with Pandas' handling of the data. If any column contained floating point numbers, we would expect to see such here, too.\n",
    "\n",
    "Now that we've viewed our dataset at a high-level, let's actually use and explore it.\n",
    "\n",
    "Recall: we can **access a column of data** the same way we access dictionary by its keys:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top50[\"Length\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could have also used this syntax (identical results):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top50.Length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want just the highest or lowest **value** of a given column, we can use the functions ``max()`` and ``min()``, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top50['Length'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top50['Length'].min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want the **row index** that corresponds to a column's max or min value, we can use ``idxmax()`` and ``idxmin()``, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top50['Length'].idxmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top50['Length'].idxmin()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also add `conditional statements` (e.g., >, <, ==) for columns, which yields a boolean vector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top50['Length'] > 240"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is useful, as it allows us to process only the rows with the True values.\n",
    "\n",
    "The **`loc()`** function allows us to access data via labels:\n",
    "- A single scalar label\n",
    "- A list of labels\n",
    "- A slice object\n",
    "- A Boolean array\n",
    "\n",
    "A single scalar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# single scalar label\n",
    "top50.loc[0] # prints the (unnamed) row that has a label of 0 (the 1st row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of labels\n",
    "top50.loc[[0,2]] # prints the (unnamed) rows that have the labels of 0 and 2 (the 1st and 3rd rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a slice of the dataframe, based on the passed-in booleans;\n",
    "# picture it's like a filter overlaying the DataFrame, and the filter\n",
    "# dictates which values will be emitted/make it through to us\n",
    "\n",
    "top50.loc[top50['Length'] > 240] # prints all rows that have Length > 240"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note, this returns a *DataFrame*. Everything we've learned so far concerns how to use DataFrames, so we can tack on additional syntax to this command if we wish to do further processing.\n",
    "\n",
    "For example, if we want to index just select columns (e.g., ArtistName, TrackName, and Length) of this returned DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top50.loc[top50['Length'] > 240][['ArtistName', 'TrackName', 'Length']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note, the above solves our original **Q1.2:** _(Write code to print all songs (Artist and Track name) that are longer than 4 minutes (240 seconds))_\n",
    "\n",
    "**Q2.4:** Write code to print the most popular song (or song(s) if there is a tie):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######\n",
    "# your code here\n",
    "#######"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also sort our data by a single column! This pertains to our original **Q1.4**!\n",
    "\n",
    "**Q2.4:** Write code to print the songs (and their attributes), if we sorted by their popularity (highest scoring ones first)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use top50.sort_values() to answer this question\n",
    "\n",
    "#######\n",
    "# your code here\n",
    "#######\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While ``.loc()`` allows us to index based on passed-in labels, ``.iloc()`` allows us to **access data based on 0-based indices.**\n",
    "\n",
    "The syntax is ``.iloc[<row selection>, <column selection>]``, where <row selection> and <column selection> can be scalars, lists, or slices of indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top50.iloc[5:6] # prints all columns for the 6th row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top50.iloc[:,2] # prints all rows for the 3rd column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top50.iloc[[0,2,3], [2,1]] # prints the 1st, 3rd, and 4th rows of the 3rd and 2nd columns (artist and track)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspecting/cleaning the data\n",
    "\n",
    "As mentioned, it is imperative to ensure the data is sound to use:\n",
    "1. Did it come from a trustworthy, authoritative source?\n",
    "2. Is the data a complete sample?\n",
    "3. Does the data seem correct?\n",
    "4. **(optional)** Is the data stored efficiently or does it have redundancies?\n",
    "\n",
    "Let's walk through each of these points now:\n",
    "\n",
    "1. Did it come from a trustworthy, authoritative source?\n",
    "\n",
    "The data came from Kaggle.com, which anyone can publish to. However, the author claims that he/she used Spotify.com's official API to query songs in 2019. There are no public comments for it so far. It's potentially credible.\n",
    "\n",
    "2. Is the data a complete sample?\n",
    "\n",
    "Pandas has functions named ``isnull()`` and ``notnull()``, which return DataFrames corresponding to any null or non-null entries, respectively.\n",
    "\n",
    "For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top50[top50.ArtistName.isnull()] # returns an empty DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "top50[top50.ArtistName.notnull()] # returns the complete DataFrame since there are no null Artists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we run this for all of our features/columns, we will see there are no nulls. Since this dataset is manageable in size, you can also just scroll through it and notice no nulls.\n",
    "\n",
    "This answers our original **Q1.5**: How could you check for null/empty entries?\n",
    "\n",
    "Continuing with our data sanity check list:\n",
    "\n",
    "3. Does the data seem correct?\n",
    "\n",
    "A quick scroll through the data, and we see a song by _Maluma_ titled _0.95833333_. This is possibly a song about probability, but I think the chances are slim. The song is 176 seconds long (2m56s). Looking on Spotify, we see **Maluma's most popular song is currently _11PM_ which is 2m56s in length!** Somehow, during the creation of the dataset, 11PM became 0.95833333. _Bonus points if you can figure out where this pointing number could have come from._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(\"fig/maluma.png\") # sample of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since only one song seems obviously wrong, we can manually fix it. And it's worth noting such to ourselves and to whomever else would see our results or receive a copy of our data. If there were many more wrong values, we'd potentialy not fix them, as we'd explore other options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top50['TrackName'][top50['ArtistName'] == \"Maluma\"] = \"11PM\"\n",
    "# Watch out for the warning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Grouping and Combining Multiple Data Frames\n",
    "\n",
    "As mentioned, often times one dataset doesn't contain all of the information you are interested in -- in which case, you need to combine data from multiple files. This also means you need to verify the accuracy (per above) of each dataset.\n",
    "\n",
    "Pandas' ``groupby()`` function splits the DataFrame into different groups, depending on the passed-in variable. For example, we can group our data by the genres:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df = top50.groupby('Genre')\n",
    "#for key, item in grouped_df:\n",
    "#    print(\"Genre:\", key, \"(\", len(grouped_df.get_group(key)), \"items):\", grouped_df.get_group(key), \"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``../data/spotify_aux.csv`` contains the same 50 songs as ``top50.csv``; however, it only contains 3 columns:\n",
    "- Track Name\n",
    "- Artist Name\n",
    "- Explicit Language (boolean valued)\n",
    "\n",
    "Note, that 3rd column is just random values, but pretend as if it's correct. The point of this section is to demonstrate how to merge columns together.\n",
    "\n",
    "Let's load ``../data/spotify_aux.csv`` into a DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explicit_lyrics = pd.read_csv(\"../data/spotify_aux.csv\")\n",
    "#explicit_lyrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's merge it with our ``top50`` DataFrame.\n",
    "\n",
    "``.merge()`` is a Pandas function that stitches together DataFrames by their columns.\n",
    "\n",
    "``.concat()`` is a Pandas function that stitches together DataFrames by their rows (if you pass axis=1 as a flag, it will be column-based)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'on='' specifies the column used as the shared key\n",
    "df_combined = pd.merge(explicit_lyrics, top50, on='TrackName')\n",
    "#df_combined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that all columns from both DataFrames have been added. That's nice, but having duplicate ArtistName and TrackName is unecessary. Since ``merge()`` uses DataFrames as the passed-in objects, we can simply pass merge() a stripped-down copy of _ExplicitLanguage_, which helps merge() not add any redundant fields. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined = pd.merge(explicit_lyrics[['TrackName', 'ExplicitLanguage']], top50, on='TrackName')\n",
    "#df_combined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This answers our original **Q1.6:** Imagine we had another table (i.e., .csv file) below. How could we combine its data with our already-existing *dataset*?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While we do not exhaustively illustrate Pandas' joining/splitting functionality, you may find the following functions useful:\n",
    "- ``merge()``\n",
    "- ``concat()``\n",
    "- ``aggregate()``\n",
    "- ``append()``"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting DataFrames\n",
    "As a very simple example of how one can plot elements of a DataFrame, we turn to Pandas' built-in plotting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_plot = top50.plot.scatter(x='Danceability', y='Popularity', c='DarkBlue')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q3.1:** Alternatively, use `plt.scatter` to recreate the scatterplot above.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######\n",
    "# your code here\n",
    "######\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shows the lack of a correlation between the Danceability of a song and its popularity, based on just the top 50 songs, of course.\n",
    "\n",
    "Please feel free to experiment with plotting other items of interest, and we recommend using Seaborn.\n",
    "\n",
    "## Practice Problems \n",
    "\n",
    "**Q3.2:** Print the shortest song (all features):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######\n",
    "# your code here\n",
    "######\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q3.3:** Print the 5 shortest songs (all features):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######\n",
    "# your code here\n",
    "######\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q3.4:**  What is the average length of the 5 shortest songs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######\n",
    "# your code here\n",
    "######\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q3.5:**  How many distinct genres are present in the top 50 songs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "######\n",
    "# your code here\n",
    "######\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q3.6:**  Print the songs that have a Danceability score above 80 and a popularity above 86. HINT: you can combine conditional statements with the & operator, and each item must be surrounded with ( ) brackets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######\n",
    "# your code here\n",
    "######\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q3.7:**  Plot a histogram of the Genre counts (x-axis is the Genres, y-axis is the # of songs with that Genre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######\n",
    "# your code here\n",
    "######"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q3.8 (open ended):** Think of a _subset_ of the data that you're interested in. Think of an interesting plot that could be shown to illustrate that data. With a partner, discuss whose would be easier to create. Together, create that plot. Then, try to create the harder plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######\n",
    "# your code here\n",
    "######"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Part 4: Beautiful Soup \n",
    "Data Engineering, the process of gathering and preparing data for analysis, is a very big part of Data Science.\n",
    "\n",
    "Datasets might not be formatted in the way you need (e.g. you have categorical features but your algorithm requires numerical features); or you might need to cross-reference some dataset to another that has a different format; or you might be dealing with a dataset that contains missing or invalid data.\n",
    "\n",
    "These are just a few examples of why data retrieval and cleaning are so important.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `requests`:  Retrieving Data from the Web"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In HW1, you will be asked to retrieve some data from the Internet. `Python` has many built-in libraries that were developed over the years to do exactly that (e.g. `urllib`, `urllib2`, `urllib3`).\n",
    "\n",
    "However, these libraries are very low-level and somewhat hard to use. They become especially cumbersome when you need to issue POST requests or authenticate against a web service.\n",
    "\n",
    "Luckly, as with most tasks in `Python`, someone has developed a library that simplifies these tasks. In reality, the requests made both on this lab and on HW1 are fairly simple, and could easily be done using one of the built-in libraries. However, it is better to get acquainted to `requests` as soon as possible, since you will probably need it in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You tell Python that you want to use a library with the import statement.\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the requests library was imported into our namespace, we can use the functions offered by it.\n",
    "\n",
    "In this case we'll use the appropriately named `get` function to issue a *GET* request. This is equivalent to typing a URL into your browser and hitting enter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the HU Wikipedia page\n",
    "req = requests.get(\"https://en.wikipedia.org/wiki/Harvard_University\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python is an Object Oriented language, and everything on it is an object. Even built-in functions such as `len` are just syntactic sugar for acting on object properties.\n",
    "\n",
    "We will not dwell too long on OO concepts, but some of Python's idiosyncrasies will be easier to understand if we spend a few minutes on this subject.\n",
    "\n",
    "When you evaluate an object itself, such as the `req` object we created above, Python will automatially call the `__str__()` or `__repr__()` method of that object. The default values for these methods are usually very simple and boring. The `req` object however has a custom implementation that shows the object type (i.e. `Response`) and the HTTP status number (200 means the request was successful)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "req"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just to confirm, we will call the `type` function on the object to make sure it agrees with the value above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(req)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another very nifty Python function is `dir`. You can use it to list all the properties of an object.\n",
    "\n",
    "By the way, properties starting with a single and double underscores are usually not meant to be called directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(req)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Right now `req` holds a reference to a *Request* object; but we are interested in the text associated with the web page, not the object itself.\n",
    "\n",
    "So the next step is to assign the value of the `text` property of this `Request` object to a variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page = req.text\n",
    "page[20000:30000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! Now we have the text of the Harvard University Wikipedia page. But this mess of HTML tags would be a pain to parse manually. Which is why we will use another very cool Python library called `BeautifulSoup`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `BeautifulSoup`\n",
    "\n",
    "Parsing data would be a breeze if we could always use well formatted data sources, such as CSV, JSON, or XML; but some formats such as HTML are at the same time a very popular and a pain to parse.\n",
    "\n",
    "One of the problems with HTML is that over the years browsers have evolved to be very forgiving of \"malformed\" syntax. Your browser is smart enough to detect some common problems, such as open tags, and correct them on the fly.\n",
    "\n",
    "Unfortunately, we do not have the time or patience to implement all the different corner cases, so we'll let BeautifulSoup do that for us.\n",
    "\n",
    "You'll notice that the `import` statement bellow is different from what we used for `requests`. The _from library import thing_ pattern is useful when you don't want to reference a function byt its full name (like we did with `requests.get`), but you also don't want to import every single thing on that library into your namespace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`BeautifulSoup` can deal with `HTML` or `XML` data, so the next line parses the contents of the `page` variable using its `HTML` parser, and assigns the result of that to the `soup` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(page, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(soup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doesn't look much different from the `page` object representation. Let's make sure the two are different types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(page)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like they are indeed different.\n",
    "\n",
    "`BeautifulSoup` objects have a cool little method that allows you to see the `HTML` content in a nice, indented way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(soup.prettify()[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like it's our page!\n",
    "\n",
    "We can now reference elements of the `HTML` document in different ways. One very convenient way is by using the dot notation, which allows us to access the elements as if they were properties of the object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is nice for `HTML` elements that only appear once per page, such the the `title` tag. But what about elements that can appear multiple times?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Be careful with elements that show up multiple times.\n",
    "soup.p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uh Oh. Turns out the attribute syntax in `Beautiful` soup is what is called *syntactic sugar*. That's why it is safer to use the explicit commands behind that syntactic sugar I mentioned. These are:\n",
    "* `BeautifulSoup.find` for getting single elements, and \n",
    "* `BeautifulSoup.find_all` for retrieving multiple elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(soup.find_all(\"p\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you look at the Wikipedia page on your browser, you'll notice that it has a couple of tables in it. We will be working with the \"Demographics\" table, but first we need to find it.\n",
    "\n",
    "One of the `HTML` attributes that will be very useful to us is the `class` attribute.\n",
    "\n",
    "Getting the class of a single element is easy!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.table[\"class\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will use a *list comprehension* to see all the tables that have a `class` attribute. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the classes of all tables that have a class attribute set on them\n",
    "[t[\"class\"] for t in soup.find_all(\"table\") if t.get(\"class\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As already mentioned, we will be using the Demographics table for this lab. The next cell contains the `HTML` elements of said table. We will render it in different parts of the notebook to make it easier to follow along the parsing steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_demographics = soup.find_all(\"table\", \"wikitable\")[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import HTML\n",
    "HTML(str(table_demographics))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we'll use a list comprehension to extract the rows (*tr*) elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rows = [row for row in table_demographics.find_all(\"tr\")]\n",
    "print(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "header_row = rows[0]\n",
    "HTML(str(header_row))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will then use a `lambda` expression to replace new line characters with spaces. `Lambda` expressions are to functions what list comprehensions are to lists: namely a more concise way to achieve the same thing.\n",
    "\n",
    "In reality, both lambda expressions and list comprehensions are a little different from their function and loop counterparts. But for the purposes of this class we can ignore those differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lambda expressions return the value of the expression inside it.\n",
    "# In this case, it will return a string with new line characters replaced by spaces.\n",
    "rem_nl = lambda s: s.replace(\"\\n\", \" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting the data\n",
    "Next we extract the text value of the columns. If you look at the table above, you'll see that we have three columns and six rows.\n",
    "\n",
    "Here we're doing the following:\n",
    "* Taking the first element (`Python` indices start at zero)\n",
    "* Iterating over the *th* elements inside it\n",
    "* Taking the text value of those elements\n",
    "\n",
    "We should end up with a list of column names.\n",
    "\n",
    "But there is one little caveat: the first column of the table is actually an empty string (look at the cell right above the row names). We could add it to our list and then remove it afterwards; but instead we will use the `if` statement inside the list comprehension to filter that out.\n",
    "\n",
    "In the following cell, `get_text` will return an empty string for the first cell of the table, which means that the test will fail and the value will not be added to the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the if col.get_text() takes care of no-text in the upper left\n",
    "columns = [rem_nl(col.get_text()) for col in header_row.find_all(\"th\") if col.get_text()]\n",
    "columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's do the same for the rows. Notice that since we have already parsed the header row, we will continue from the second row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes = [row.find(\"th\").get_text() for row in rows[1:]]\n",
    "indexes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to transform the string on the cells to integers.  To do this, we follow a very common `python` pattern:\n",
    "1. Check if the last character of the string is a percent sign\n",
    "2. If it is, then convert the characters before the percent sign to integers\n",
    "3. If one of the prior checks fails, return a value of `None`\n",
    "\n",
    "These steps can be conveniently packaged into a function using `if-else` statements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_num(s):\n",
    "    if s[-1] == \"%\":\n",
    "        return int(s[:-1])\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the `Python` slices are open on the upper bound. So the `[:-1]` construct will return all elements of the string, except for the last."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another nice way to write our `to_num` function would be\n",
    "```python\n",
    "def to_num(s):\n",
    "    return int(s[:-1]) if s[-1] == \"%\" else None\n",
    "```\n",
    "Notice that we only had to write `return` one time and everything conveniently fits on one line.  I'll leave it up to you to decide if it's readable or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we use the `to_num` function in a list comprehension to parse the table values.\n",
    "\n",
    "Notice that we have two `for ... in ...` in this list comprehension. That is perfectly valid and somewhat common.\n",
    "\n",
    "Although there is no real limit to how many iterations you can perform at once, having more than two can be visually unpleasant, at which point either regular nested loops or saving intermediate comprehensions might be a better solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = [to_num(value.get_text()) for row in rows[1:] for value in row.find_all(\"td\")]\n",
    "values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problem with the list above is that the values lost their grouping.\n",
    "\n",
    "The `zip` function is used to combine two sequences element wise. So \n",
    "```python\n",
    "zip([1,2,3], [4,5,6])\n",
    "```\n",
    "would return\n",
    "```python\n",
    "[(1, 4), (2, 5), (3, 6)]\n",
    "```\n",
    "\n",
    "Next we create three arrays corresponding to the three columns by putting every three values in each list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_values_lists = [values[i::3] for i in range(len(columns))]\n",
    "stacked_values_lists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then use `zip`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_values = zip(*stacked_values_lists)\n",
    "list(stacked_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the use of the `*` in front: that converts the list of lists to a set of arguments to `zip`. See the ASIDE below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here's the original HTML table for visual understanding\n",
    "HTML(str(table_demographics))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q4.1:** Use the tables in `soup` to determine how Harvard's Computer Science program ranks both Nationally and Globally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######\n",
    "# your code here\n",
    "######\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
